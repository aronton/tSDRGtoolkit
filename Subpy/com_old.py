import os
import math
import time
import timeit
import numpy as np
import sys
import tarfile
import datetime
import multiprocessing
import scriptCreator
from pathlib import Path
import shutil
import fcntl



dicosPath = "/ceph/work/NTHU-qubit/LYT/tSDRG_random"
scopionPath = "/home/aronton/tSDRG_random"

if os.path.isdir(dicosPath):
    tSDRG_path = dicosPath
    group_path = dicosPath
    
if os.path.isdir(scopionPath):
    tSDRG_path = scopionPath
    group_path = scopionPath
    
sourcelist = {"ZL":"ZL.csv", "energy":"energy.csv", "seed":"s_re_seed.csv",\
    "corr1":"_".join(["L_re","P_re","m_re","s_re","corr1.csv"]), "corr2":"_".join(["L_re","P_re","m_re","s_re","corr2.csv"]),\
    "ZLI":"ZLI.csv", "ZLC":"ZLC.csv", "w_loc":"w_loc.csv", "J_list":"J_list.csv", "dimerization":"dimerization.csv",\
    "string":"_".join(["L_re","P_re","m_re","s_re","string.csv"])
    }

grouplist = {"ZL":"_".join(["L_re","P_re","m_re","s_re","ZL.txt"]), "energy":"_".join(["L_re","P_re","m_re","s_re","energy.txt"]),\
    "corr1":"_".join(["L_re","P_re","m_re","s_re","corr1.txt"]), "corr2":"_".join(["L_re","P_re","m_re","s_re","corr2.txt"]),\
    "ZLI":"_".join(["L_re","P_re","m_re","s_re","ZLI.txt"]), "ZLC":"_".join(["L_re","P_re","m_re","s_re","ZLC.txt"]),\
    "w_loc":"_".join(["L_re","P_re","m_re","s_re","w_loc.txt"]), "J_list":"_".join(["L_re","P_re","m_re","s_re","J_list.txt"]),\
    "string":"_".join(["L_re","P_re","m_re","s_re","string.txt"]), "seed":"_".join(["L_re","P_re","m_re","s_re","seed.txt"]),\
    "dimerization":"_".join(["L_re","P_re","m_re","s_re","dimerization.txt"])
    }

tarlist = {
    "ZL":"_".join(["ZL","L_re","P_re","m_re","J_re","D_re.txt"]),\
    "energy":"_".join(["energy","L_re","P_re","m_re","J_re","D_re.txt"]),\
    "corr1":"_".join(["corr1","L_re","P_re","m_re","J_re","D_re.txt"]),\
    "corr2":"_".join(["corr2","L_re","P_re","m_re","J_re","D_re.txt"]),\
    "ZLI":"_".join(["ZLI","L_re","P_re","m_re","J_re","D_re.txt"]),\
    "ZLC":"_".join(["ZLC","L_re","P_re","m_re","J_re","D_re.txt"]),\
    "w_loc":"_".join(["w_loc","L_re","P_re","m_re","J_re","D_re.txt"]),\
    "J_list":"_".join(["J_list","L_re","P_re","m_re","J_re","D_re.txt"]),\
    "string":"_".join(["string","L_re","P_re","m_re","J_re","D_re.txt"]),\
    "seed":"_".join(["seed","L_re","P_re","m_re.txt"]),
    "dimerization":"_".join(["dimerization","L_re","P_re","m_re.txt"])
    }
metalist = {
    "ZL":"_".join(["ZL","L_re","P_re","m_re","J_re","D_re.txt"]),\
    "energy":"_".join(["gap","L_re","P_re","m_re","J_re","D_re.txt"]),\
    "corr1":"_".join(["corr1","L_re","P_re","m_re","J_re","D_re","dx_re.txt"]),\
    "corr2":"_".join(["corr2","L_re","P_re","m_re","J_re","D_re","dx_re.txt"]),\
    }

metaDislist = {
    "ZL":"_".join(["ZL_dis","L_re","P_re","m_re","J_re","D_re.txt"]),\
    "energy":"_".join(["gap_dis","L_re","P_re","m_re","J_re","D_re.txt"]),\
    "corr1":"_".join(["corr1_dis","L_re","P_re","m_re","J_re","D_re","dx_re.txt"]),\
    "corr2":"_".join(["corr2_dis","L_re","P_re","m_re","J_re","D_re","dx_re.txt"]),\
    }


def creatName(BC, J, D, L, P, m, phys):
    mySourceName = sourcelist[phys].replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m) 
    myTargetName = tarlist[phys].replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m) 
    groupSourceName = grouplist[phys].replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m) 
    groupTargetName = tarlist[phys].replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m) 
    groupAveName = metalist[phys].replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m)
    groupDisName = metaDislist[phys].replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m)
    return (mySourceName, groupSourceName, myTargetName, groupTargetName, groupAveName, groupDisName)

def creatDir(BC, J, D, L, P, m, phys):
    avePath = "/".join(["tSDRG","Main_15","metadata_old","BC_re","J_re","D_re","L_re_P_re_m_re_s_re"])
    sourcePath = "/".join(["tSDRG","Main_15","data_tar","BC_re","J_re","D_re","L_re_P_re_m_re_s_re"])
    tarPath = "/".join(["tSDRG","Main_15","data_collect_old","BC_re","J_re","D_re","L_re_P_re_m_re"])
    mySourcePathBase = "/".join([tSDRG_path,sourcePath])
    groupSourcePathBase = "/".join([group_path,sourcePath])
    myTargetPathBase = "/".join([tSDRG_path,tarPath])
    groupTargetPathBase = "/".join([group_path,tarPath])
    avePathBase = "/".join([tSDRG_path,avePath])
    # disPathBase = "/".join([tSDRG_path,avePath])
    # sourcePathBase = f"{tSDRG_path}/tSDRG/Main_15/data_random/BC_re/J_re/D_re/L_re_P_re_m_re_s_re/"
    # cpPathBase = f"{group_path}/tSDRG/Main_15/data_random/BC_re/J_re/D_re/L_re_P_re_m_re_s_re/"
    # targetPathBase = f"{group_path}/tSDRG/Main_15/data_collect/BC_re/J_re/D_re/L_re_P_re_m_re/"

    mySourcePath = mySourcePathBase.replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m)
    groupSourcePath = groupSourcePathBase.replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m)
    myTargetPath = myTargetPathBase.replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m)
    groupTargetPath = groupTargetPathBase.replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m)
    myAvePath = avePathBase.replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m).replace("s_re", "meta")
    myDisPath = avePathBase.replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m).replace("s_re", "dis")
    # cpPath = cpPathBase.replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m)
    # targetPath = targetPathBase.replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m)
    
    return (mySourcePath, groupSourcePath, myTargetPath, groupTargetPath, myAvePath, myDisPath)

def gapAverage(BC, J, D, L, P, m, phys):
    folder = creatDir(BC, J, D, L, P, m, phys)
    name = creatName(BC, J, D, L, P, m, phys)
    myTarPath = folder[2] + "/" + name[2]

    gaplist = []
    try:
        with open(myTarPath, "r") as targetFile:
            collect = targetFile.readlines()
            collect = [line.strip() for line in collect]
            if collect and collect[0] == "energy":
                del collect[0]
            for line in collect:
                line = line.split(":")[-1].split(" ")
                try:
                    gap = float(line[1]) - float(line[0])
                    gaplist.append(gap)
                except Exception as e:
                    print(e)
    except FileNotFoundError:
        print(f"File not found: {myTarPath}")
        return False, False, False
    save_gapDistribute(gaplist, BC, J, D, L, P, m, phys)
    gapAve = np.mean(gaplist)
    sample = len(gaplist) 
    error = np.std(gaplist, ddof=1)

    return gapAve, sample, error

def save_gapDistribute(gaplist, BC, J, D, L, P, m, phys):
    folder = creatDir(BC, J, D, L, P, m, phys)
    name = creatName(BC, J, D, L, P, m, phys)
    # print( f"folder[4]:{folder[4]}")
    gapDisBase = folder[5] + "/" + name[5]
    context = "ground_state_gap\n"
    for i, value in enumerate(gaplist):
        context += f"{value}\n"
    
    if context == "ground_state_gap\n":
        return
    else:
        if not os.path.exists(gapDisBase):
            os.makedirs(os.path.dirname(gapDisBase), exist_ok=True)
        with open(gapDisBase, "w") as targetFile:
            targetFile.write(context)

def save_gap(BC, J, D, L, P, m, phys):
    gapAve, sample, error = gapAverage(BC, J, D, L, P, m, phys)
    if gapAve == False:
        print(f"Error: No data found for {BC}, {J}, {D}, {L}, {P}, {m}, {phys}")
        return
    folder = creatDir(BC, J, D, L, P, m, phys)
    name = creatName(BC, J, D, L, P, m, phys)
    # print( f"folder[4]:{folder[4]}")
    myTarPath = folder[4] + "/" + name[4]
    # print(f"myTarPath:{myTarPath}")
    if not os.path.exists(myTarPath):
        os.makedirs(os.path.dirname(myTarPath), exist_ok=True)
    with open(myTarPath, "w") as targetFile:
        targetFile.write(f"ground_state_energy, sample, error\n{gapAve}, {sample}, {error/math.sqrt(sample)}")
            
def corrAverage(BC, J, D, L, P, m, phys):
    folder = creatDir(BC, J, D, L, P, m, phys)
    name = creatName(BC, J, D, L, P, m, phys)
    myTarPath = folder[2] + "/" + name[2]

    corrDic = {}
    try:
        with open(myTarPath, "r") as targetFile:
            collect = targetFile.readlines()
            collect = [line.strip() for line in collect]
            if collect and collect[0] == "corr1":
                del collect[0]
            for line in collect:
                line = line.split(":")[-1].split(" ")
                for data in line:
                    if data:
                        parts = data.split(",")
                        if len(parts) >= 3:
                            try:
                                x1, x2 = int(parts[0]), int(parts[1])
                                corr = float(parts[2])
                                key = x2 - x1
                                if key not in corrDic:
                                    corrDic[key] = []
                                corrDic[key].append(corr)
                            except ValueError:
                                continue  # å¿½ç•¥ç„¡æ³•è½‰æ›çš„æ•¸æ“š
    except FileNotFoundError:
        print(f"File not found: {myTarPath}")
        return False, False, False
    save_corrDistribute(corrDic, BC, J, D, L, P, m, phys)
    corr = {}
    sample = {}
    error = {}
    for key, values in corrDic.items():
        sample[key] = len(values)
        corr[key] = np.mean(values)
        error[key] = np.std(values, ddof=1) if len(values) > 1 else 0.0

    return corr, sample, error

def save_corrDistribute(corrDic, BC, J, D, L, P, m, phys):
    folder = creatDir(BC, J, D, L, P, m, phys)
    name = creatName(BC, J, D, L, P, m, phys)
    # print( f"folder[4]:{folder[4]}")
    corrDisBase = folder[5] + "/" + name[5]
    for key, values in corrDic.items():
        context = ""
        if BC == "OBC":
            context = f"C_etoe=<S(0)S(dx={key})>\n"
        elif BC == "PBC":
            context = f"C_bulk=<S(0)S(dx={key})>\n"
        corrDisPath = corrDisBase.replace("dx_re", f"dx={key}")
        for value in values:
            context += f"{value}\n"
        
        if context == f"C_etoe=<S(0)S(dx={key})>\n" or context ==  f"C_bulk=<S(0)S(dx={key})>\n":
            continue
        else:
            if not os.path.exists(corrDisPath):
                os.makedirs(os.path.dirname(corrDisPath), exist_ok=True)
            with open(corrDisPath, "w") as targetFile:
                targetFile.write(context)

def save_corr(BC, J, D, L, P, m, phys):
    corr, sample, error = corrAverage(BC, J, D, L, P, m, phys)
    if corr == False:
        print(f"Error: No data found for {BC}, {J}, {D}, {L}, {P}, {m}, {phys}")
        return
    folder = creatDir(BC, J, D, L, P, m, phys)
    name = creatName(BC, J, D, L, P, m, phys)
    # print( f"folder[4]:{folder[4]}")
    myTarPathBase = folder[4] + "/" + name[4]
    # print(f"myTarPath:{myTarPath}")

    for key in corr.keys():
        if corr[key] == None:
            continue
        myTarPath = myTarPathBase.replace("dx_re", f"dx={key}")
        if BC == "OBC":
            context = f"C_etoe=<S(0)S(dx={key})>,sample,errorbar\n" + f"{corr[key]},{sample[key]},{error[key]/math.sqrt(sample[key])}"
        elif BC == "PBC":
            context = f"C_bulk=<S(0)S(dx={key})>,sample,errorbar\n" + f"{corr[key]},{sample[key]},{error[key]/math.sqrt(sample[key])}"
        if not os.path.exists(myTarPath):
            os.makedirs(os.path.dirname(myTarPath), exist_ok=True)
        with open(myTarPath, "w") as targetFile:
            targetFile.write(context)


def ZLAverage(BC, J, D, L, P, m, phys, context=None):
    folder = creatDir(BC, J, D, L, P, m, phys)
    name = creatName(BC, J, D, L, P, m, phys)
    myTarPath = folder[2] + "/" + name[2]
    zllist = []
    
    try:
        if context is None:
            if not os.path.exists(myTarPath):
                raise FileNotFoundError(f"{myTarPath} does not exist")
            auto_delete_empty = True
            if os.path.getsize(myTarPath) == 0:
                if auto_delete_empty:
                    os.remove(myTarPath)
                    print(f"[åˆªé™¤] ç©ºæª”æ¡ˆå·²åˆªé™¤ï¼š{myTarPath}")
                raise ValueError("æª”æ¡ˆç‚ºç©º")
            with open(myTarPath, "r") as targetFile:
                zllist = targetFile.readlines()
                if "ZL" in zllist[0]:
                    del zllist[0]
        else:
            zllist = context.rstrip().split("\n")
            if "ZL" in zllist[0]:
                del zllist[0]
        zllist = [float(line.split(":")[-1]) for line in zllist]
        if not zllist:
            if auto_delete_empty:
                os.remove(myTarPath)
                print(f"[åˆªé™¤] ç©ºæª”æ¡ˆå·²åˆªé™¤ï¼š{myTarPath}")
            raise ValueError("æª”æ¡ˆå…§å®¹ç‚ºç©º")
    except FileNotFoundError:
        print(f"File not found: {myTarPath}")
        return False, False, False
    except ValueError as e:
        print(f"è·³éç©ºæª”æ¡ˆ: {BC}, {J}, {D}, {L}, {P}, {m}, {phys} â†’ {e}")
        return False, False, False
    save_zlDistribute(zllist, BC, J, D, L, P, m, phys)
    zlAve = np.mean(zllist)
    sample = len(zllist)
    error = np.std(zllist, ddof=1)

    return zlAve, sample, error

def save_zlDistribute(zllist, BC, J, D, L, P, m, phys):
    folder = creatDir(BC, J, D, L, P, m, phys)
    name = creatName(BC, J, D, L, P, m, phys)
    # print( f"folder[4]:{folder[4]}")
    zlDisBase = folder[5] + "/" + name[5]
    context = "ZL\n"
    for i, value in enumerate(zllist):
        context += f"{value}\n"
    if context == "ZL\n":
        return
    else:
        if not os.path.exists(zlDisBase):
            os.makedirs(os.path.dirname(zlDisBase), exist_ok=True)
        with open(zlDisBase, "w") as targetFile:
            targetFile.write(context)

def save_ZL(BC, J, D, L, P, m, phys, context=None):
    zlAve, sample, error = ZLAverage(BC, J, D, L, P, m, phys, context)
    if zlAve == False:
        print(f"Error: No data found for {BC}, {J}, {D}, {L}, {P}, {m}, {phys}")
        return
    folder = creatDir(BC, J, D, L, P, m, phys)
    name = creatName(BC, J, D, L, P, m, phys)
    # print( f"folder[4]:{folder[4]}")
    myTarPath = folder[4] + "/" + name[4]

    if not os.path.exists(myTarPath):
        os.makedirs(os.path.dirname(myTarPath), exist_ok=True)
    with open(myTarPath, "w") as targetFile:
        targetFile.write(f"ZL, sample, errorbar\n{zlAve}, {sample}, {error/math.sqrt(sample)}")    
# def save_gap():

def list_txt_files(directory):
    txt_files = []
    for root, _, files in os.walk(directory):
        for file in files:
            if file.endswith('.txt'):
                full_path = os.path.join(root, file)
                txt_files.append(full_path)
    return txt_files            

def checkInside(s, f, sample, phys):
    with open(f,"r") as a:
        a = a.readlines()    
        if a[0].strip() == phys:
            del a[0]
        data = [(v.split(":")[0].strip(),(v.split(":")[1].replace("\n"," ").strip())) for i,v in enumerate(a)]
        sorted_data = sorted(data, key=lambda x: int(x[0]))
    if s == sorted_data[sample+1][1]:
        return True
    else:
        return False


def compare(f1, f2, sample):
    # è®€å–å…©å€‹æª”æ¡ˆ
    try:
        with open(f1, "r") as file1:
            a = [line.strip() for line in file1 if line.strip()]
        with open(f2, "r") as file2:
            b = [line.strip() for line in file2 if line.strip()]
    except FileNotFoundError:
        print(f"æª”æ¡ˆä¸å­˜åœ¨ï¼š{f1} æˆ– {f2}")
        return False

    # è‹¥æœ‰ä»»ä¸€æª”æ¡ˆç‚ºç©ºï¼Œç›´æ¥åˆ¤å®šä¸åŒ
    if not a or not b:
        return False

    # å…©é‚Šéƒ½å¾ˆçŸ­ï¼ˆ1-2 è¡Œï¼‰ï¼Œç›´æ¥æ¯”å°æ•´é«”å…§å®¹
    if len(a) <= 2 and len(b) <= 2:
        return a == b

    # å…©é‚Šéƒ½æœ‰å¤šè¡Œï¼Œç›´æ¥æ¯”å°æ•´é«”å…§å®¹
    if len(a) > 2 and len(b) > 2:
        return a == b

    # ---- ä»¥ä¸‹ç‚ºä¸å°ç¨±æ¯”å°æƒ…æ³ ----

    # æŠŠ a è¨­ç‚ºçŸ­çš„é‚£ä¸€ä»½ï¼Œb ç‚ºé•·çš„ï¼ˆæ–¹ä¾¿è™•ç†ï¼‰
    if len(a) > len(b):
        a, b = b, a  # swap

    # è‹¥ a æœ‰ 2 è¡Œï¼Œå…ˆåˆªæ‰æ¨™é¡Œè¡Œ
    if len(a) == 2:
        data1 = a[1]
    else:
        data1 = a[0]

    # ç§»é™¤ b çš„æ¨™é¡Œè¡Œ
    b = b[1:]

    # åœ¨ b è£¡æœå°‹ data1 å°æ‡‰åˆ°çš„ sample åç¨±
    for line in b:
        if data1 in line:
            parts = line.split(":")
            if parts[0] == sample:
                return True

    return False

def checkFileNum(dirpath):
    folder = Path(dirpath) 
    file_count = sum(1 for f in folder.iterdir() if f.is_file())
    return file_count

def fread(f, phys):
    if os.path.exists(f):
        with open(f,"r") as a:
            a = a.readlines()
            if len(a) == 0:
                return 
            else:
                if phys in a[0].strip():
                    del a[0]
                a = "".join(a)
                a = a.replace("\n"," ")
                return a
    else:
        return 

def create_tarball_files(output_filename, file_list):
    with tarfile.open(output_filename, "w:gz") as tar:
        for file in file_list:
            tar.add(file, arcname=file)  # arcname ä¿æŒåŸå§‹æª”å
    print(f"å·²æ‰“åŒ… {len(file_list)} å€‹æª”æ¡ˆåˆ° {output_filename}")

def kill_files(file_list):
    for i,f in enumerate(file_list):
        os.system("rm " + f)
    return f"å·²åˆªé™¤ {len(file_list)} å€‹æª”æ¡ˆï¼Œå¾{file_list[0]}åˆ°{file_list[-1]}"
    
def cp_files(file_list):
    for i,f in enumerate(file_list):
        os.system("cp " + f)
    print(f"å·²è¤‡è£½ {len(file_list)} å€‹æª”æ¡ˆï¼Œå¾{file_list[0]}åˆ°{file_list[-1]}")



def parse_context(context):
    """
    å°‡åŸå§‹å­—ä¸²è§£æç‚ºéµå€¼å°åˆ—è¡¨ã€‚
    """
    lines = [line.strip() for line in context.strip().split('\n') if line.strip()]
    pairs = []
    for line in lines:
        if ':' in line:
            key_value = line.split(':', 1)
            if len(key_value) == 2:
                key_str, value = key_value
                try:
                    key_int = int(key_str.strip())
                    pairs.append((key_int, value.strip()))
                except ValueError:
                    continue
    return pairs

def is_sorted(pairs):
    """
    æª¢æŸ¥éµå€¼å°åˆ—è¡¨æ˜¯å¦å·²æŒ‰éµçš„å‡åºæ’åºã€‚
    """
    return all(pairs[i][0] <= pairs[i + 1][0] for i in range(len(pairs) - 1))

def sort_context(pairs):
    """
    å°éµå€¼å°åˆ—è¡¨æŒ‰éµé€²è¡Œæ’åºï¼Œä¸¦é‡å»ºç‚ºå­—ä¸²æ ¼å¼ã€‚
    """
    sorted_pairs = sorted(pairs, key=lambda x: x[0])
    s1 = sorted_pairs[0][0]  # å‡è¨­ç¬¬ä¸€å€‹éµæ˜¯ s1
    sorted_lines = [f"{key}:{value}" for key, value in sorted_pairs]
    return '\n'.join(sorted_lines), s1

def sort_if_needed(context):
    """
    è‹¥è³‡æ–™æœªæ’åºï¼Œå‰‡é€²è¡Œæ’åºï¼›å¦å‰‡è¿”å›åŸå§‹è³‡æ–™ã€‚
    """
    pairs = parse_context(context)
    if is_sorted(pairs):
        print("è³‡æ–™å·²æ’åºï¼Œç„¡éœ€æ’åºã€‚")
        s1 = int(pairs[0][0])  # å‡è¨­ç¬¬ä¸€å€‹éµæ˜¯ s1
        return context, s1
    else:
        print("è³‡æ–™æœªæ’åºï¼Œé–‹å§‹æ’åºã€‚")
        return sort_context(pairs)
        
def Combine(BC, J, D, L, P, m, phys, s1, s2):
    folder = creatDir(BC, J, D, L, P, m, phys)
    name = creatName(BC, J, D, L, P, m, phys)

    mySourcePath = folder[0] + "/" + name[0]
    groupSourcePath = folder[1] + "/" + name[1]
    myTarPath = folder[2] + "/" + name[2]
    groupTarPath = folder[3] + "/" + name[3]

    seedArray = list(range(s1, s2 + 1))
    # with open(groupTarPath, "r") as originFile:
    #     originaText = originFile.readlines()
    context = ""
    # print("originaText")
    for seed in seedArray:
        groupSource = groupSourcePath.replace("s_re", str(seed))
        mySource = mySourcePath.replace("s_re", str(seed))
        # if f"{seed}:" in originaText[seed-1]:
        #     continue
        if os.path.exists(groupSource) and os.path.exists(mySource):
            if compare(groupSource, mySource, seed):                
                fcontext = fread(mySource, phys)
            else:
                # os.remove(groupSource)
                shutil.copy(mySource, groupSource)
                fcontext = fread(groupSource, phys)
        elif os.path.exists(mySource):
            # os.makedirs(os.path.dirname(groupSource), exist_ok=True)
            shutil.copy(mySource, groupSource)
            # os.remove(mySource)
            fcontext = fread(groupSource, phys)
        elif os.path.exists(groupSource):
            fcontext = fread(groupSource, phys)
        else:
            continue

        if fcontext is not None:
            context += f"{seed}:{fcontext}\n"

    if context != "":
        context, s1 = sort_if_needed(context)
        
        save_context(context, s1, groupTarPath, myTarPath, phys)
        # os.makedirs(os.path.dirname(myTarPath), exist_ok=True)


def save_context(context, s1, groupTarPath, myTarPath, phys):
    if not os.path.exists(groupTarPath):
        os.makedirs(os.path.dirname(groupTarPath), exist_ok=True)

    mode = "w" if s1 == 1 else "a"

    if s1 == 1:
        context = f"{phys}\n{context}"

    with open(groupTarPath, mode) as f1:
        try:
            # å˜—è©¦éé˜»å¡åŠ é–
            fcntl.flock(f1, fcntl.LOCK_EX | fcntl.LOCK_NB)
            print(f"âœ… ç«‹å³å–å¾—é– [PID {os.getpid()}] ({'WRITE' if s1==1 else 'APPEND'}): {groupTarPath}")
        except BlockingIOError:
            print(f"â³ é–ä½ç­‰å¾…ä¸­ [PID {os.getpid()}] â†’ {groupTarPath}")
            fcntl.flock(f1, fcntl.LOCK_EX)
            print(f"âœ… æœ€çµ‚å–å¾—é– [PID {os.getpid()}]")

        try:
            f1.write(context)
        finally:
            fcntl.flock(f1, fcntl.LOCK_UN)
            print(f"ğŸ”“ æª”æ¡ˆå·²è§£é– [PID {os.getpid()}] â†’ {groupTarPath}")
    

        
def parameter_read_dict(filename):
    parameters = {}
    try:
        with open(filename, 'r', encoding='utf-8') as file:
            for line in file:
                if ':' in line:
                    key, value = line.split(':', 1)
                    key = key.strip()
                    value = value.strip()
                    if key:
                        parameters[key] = value
    except FileNotFoundError:
        print(f"ç„¡æ³•é–‹å•Ÿæª”æ¡ˆ: {filename}")
    
    return parameters


            
if __name__ == "__main__":
    # file = sys.argv[1]
    arg = []
    # Jstr = [f"Jdis{str(i).zfill(3)}" for i in range(int(J),int(J)+1)]
    Jstr = [f"Jdis{str(i).zfill(3)}" for i in range(51,201)]

    Dstr = [f"Dim{str(i).zfill(3)}" for i in range(101)]
    # Lstr = [f"L{num}" for num in range(31, 255, 32)]  # åªæœ‰ L512
    Lstr = [f"L{num}" for num in range(64, 550, 64)]  # åªæœ‰ L512
    chi = "m40"
    BC = "PBC"
    s1 = 1
    s2 = 10000
    Pdis = 10
    # a = scriptCreator.para("read",file)
    # parameterlist = a.para
    # para=scriptCreator.paraList1(parameterlist["L"],parameterlist["J"],parameterlist["D"],parameterlist["S"])
    # BC = parameterlist["BC"]
    # Pdis = parameterlist["Pdis"]
    # chi = "m" + str(parameterlist["chi"])
    # s1 = int(parameterlist["S"]["S1"])
    # s2 = int(parameterlist["S"]["S2"])
    # s1 = int(sys.argv[2])
    # s2 = int(sys.argv[3])
    if BC == "PBC":
        s_list = ["ZL","corr1","corr2","string","J_list","energy","dimerization","w_loc","seed"]
    else:
        s_list = ["ZL","corr1","corr2","J_list","energy","dimerization","w_loc","seed"]
        
    # for s in s_list:
    #     for L in para.L_str:
    #         for J in para.J_str:
    #                 arg.append((BC, J, para.D_str[0], L, f"P{Pdis}", f"{chi}", s, s1, s2))
    for s in s_list:
        for L in Lstr:
            for J in Jstr:
                for D in Dstr:
                    arg.append((BC, J, D, L, f"P{Pdis}", f"{chi}", s, s1, s2))
    print(s_list)  
    print(Lstr)
    print(Jstr)
    print(Dstr)         

    def fun(arg):
        print("---------------------col--------------------\n")
        with multiprocessing.Pool(processes=30) as pool:
            results1 = pool.starmap(Combine, arg)
        # print("---------------------del--------------------\n")
        # with multiprocessing.Pool(processes=20) as pool:
        #     results1 = pool.starmap(checkAndDelete, arg)
            
    # è¨ˆç®—å‡½æ•¸åŸ·è¡Œæ™‚é–“
    execution_time = timeit.timeit(lambda: fun(arg), number=1)

    # åŸ·è¡Œä¸¦é¡¯ç¤ºçµæœ
    # results1, results2 = fun(arg)
    print(f"Execution time: {execution_time} seconds")    