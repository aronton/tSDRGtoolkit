import os
import math
import time
import timeit
import numpy as np
import sys
import tarfile
import datetime
import multiprocessing
import scriptCreator
from pathlib import Path
import shutil
import fcntl



dicosPath = "/ceph/work/NTHU-qubit/LYT/tSDRG_random"
scopionPath = "/home/aronton/tSDRG_random"

if os.path.isdir(dicosPath):
    tSDRG_path = dicosPath
    group_path = dicosPath
    
if os.path.isdir(scopionPath):
    tSDRG_path = scopionPath
    group_path = scopionPath
    
sourcelist = {"ZL":"ZL.csv", "energy":"energy.csv", "seed":"s_re_seed.csv",\
    "corr1":"_".join(["L_re","P_re","m_re","s_re","corr1.csv"]), "corr2":"_".join(["L_re","P_re","m_re","s_re","corr2.csv"]),\
    "ZLI":"ZLI.csv", "ZLC":"ZLC.csv", "w_loc":"w_loc.csv", "J_list":"J_list.csv", "dimerization":"dimerization.csv",\
    "string":"_".join(["L_re","P_re","m_re","s_re","string.csv"])
    }

grouplist = {"ZL":"_".join(["L_re","P_re","m_re","s_re","ZL.txt"]), "energy":"_".join(["L_re","P_re","m_re","s_re","energy.txt"]),\
    "corr1":"_".join(["L_re","P_re","m_re","s_re","corr1.txt"]), "corr2":"_".join(["L_re","P_re","m_re","s_re","corr2.txt"]),\
    "ZLI":"_".join(["L_re","P_re","m_re","s_re","ZLI.txt"]), "ZLC":"_".join(["L_re","P_re","m_re","s_re","ZLC.txt"]),\
    "w_loc":"_".join(["L_re","P_re","m_re","s_re","w_loc.txt"]), "J_list":"_".join(["L_re","P_re","m_re","s_re","J_list.txt"]),\
    "string":"_".join(["L_re","P_re","m_re","s_re","string.txt"]), "seed":"_".join(["L_re","P_re","m_re","s_re","seed.txt"]),\
    "dimerization":"_".join(["L_re","P_re","m_re","s_re","dimerization.txt"])
    }

tarlist = {
    "ZL":"_".join(["ZL","L_re","P_re","m_re","J_re","D_re.txt"]),\
    "energy":"_".join(["energy","L_re","P_re","m_re","J_re","D_re.txt"]),\
    "corr1":"_".join(["corr1","L_re","P_re","m_re","J_re","D_re.txt"]),\
    "corr2":"_".join(["corr2","L_re","P_re","m_re","J_re","D_re.txt"]),\
    "ZLI":"_".join(["ZLI","L_re","P_re","m_re","J_re","D_re.txt"]),\
    "ZLC":"_".join(["ZLC","L_re","P_re","m_re","J_re","D_re.txt"]),\
    "w_loc":"_".join(["w_loc","L_re","P_re","m_re","J_re","D_re.txt"]),\
    "J_list":"_".join(["J_list","L_re","P_re","m_re","J_re","D_re.txt"]),\
    "string":"_".join(["string","L_re","P_re","m_re","J_re","D_re.txt"]),\
    "seed":"_".join(["seed","L_re","P_re","m_re.txt"]),
    "dimerization":"_".join(["dimerization","L_re","P_re","m_re.txt"])
    }
            

def checkInside(s, f, sample, phys):
    with open(f,"r") as a:
        a = a.readlines()    
        if a[0].strip() == phys:
            del a[0]
        data = [(v.split(":")[0].strip(),(v.split(":")[1].replace("\n"," ").strip())) for i,v in enumerate(a)]
        sorted_data = sorted(data, key=lambda x: int(x[0]))
    if s == sorted_data[sample+1][1]:
        return True
    else:
        return False


def compare(f1, f2, sample):
    # è®€å–å…©å€‹æª”æ¡ˆ
    try:
        with open(f1, "r") as file1:
            a = [line.strip() for line in file1 if line.strip()]
        with open(f2, "r") as file2:
            b = [line.strip() for line in file2 if line.strip()]
    except FileNotFoundError:
        print(f"æª”æ¡ˆä¸å­˜åœ¨ï¼š{f1} æˆ– {f2}")
        return False

    # è‹¥æœ‰ä»»ä¸€æª”æ¡ˆç‚ºç©ºï¼Œç›´æ¥åˆ¤å®šä¸åŒ
    if not a or not b:
        return False

    # å…©é‚Šéƒ½å¾ˆçŸ­ï¼ˆ1-2 è¡Œï¼‰ï¼Œç›´æ¥æ¯”å°æ•´é«”å…§å®¹
    if len(a) <= 2 and len(b) <= 2:
        return a == b

    # å…©é‚Šéƒ½æœ‰å¤šè¡Œï¼Œç›´æ¥æ¯”å°æ•´é«”å…§å®¹
    if len(a) > 2 and len(b) > 2:
        return a == b

    # ---- ä»¥ä¸‹ç‚ºä¸å°ç¨±æ¯”å°æƒ…æ³ ----

    # æŠŠ a è¨­ç‚ºçŸ­çš„é‚£ä¸€ä»½ï¼Œb ç‚ºé•·çš„ï¼ˆæ–¹ä¾¿è™•ç†ï¼‰
    if len(a) > len(b):
        a, b = b, a  # swap

    # è‹¥ a æœ‰ 2 è¡Œï¼Œå…ˆåˆªæ‰æ¨™é¡Œè¡Œ
    if len(a) == 2:
        data1 = a[1]
    else:
        data1 = a[0]

    # ç§»é™¤ b çš„æ¨™é¡Œè¡Œ
    b = b[1:]

    # åœ¨ b è£¡æœå°‹ data1 å°æ‡‰åˆ°çš„ sample åç¨±
    for line in b:
        if data1 in line:
            parts = line.split(":")
            if parts[0] == sample:
                return True

    return False

def checkFileNum(dirpath):
    folder = Path(dirpath) 
    file_count = sum(1 for f in folder.iterdir() if f.is_file())
    return file_count

def creatName(BC, J, D, L, P, m, phys):
    mySourceName = sourcelist[phys].replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m) 
    myTargetName = tarlist[phys].replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m) 
    groupSourceName = grouplist[phys].replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m) 
    groupTargetName = tarlist[phys].replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m) 
    return (mySourceName, groupSourceName, myTargetName, groupTargetName)

def creatDir(BC, J, D, L, P, m, phys):
    sourcePath = "/".join(["tSDRG","Main_15","data_random","BC_re","J_re","D_re","L_re_P_re_m_re_s_re"])
    tarPath = "/".join(["tSDRG","Main_15","data_collect","BC_re","J_re","D_re","L_re_P_re_m_re"])
    mySourcePathBase = "/".join([tSDRG_path,sourcePath])
    groupSourcePathBase = "/".join([group_path,sourcePath])
    myTargetPathBase = "/".join([tSDRG_path,tarPath])
    groupTargetPathBase = "/".join([group_path,tarPath])
    # sourcePathBase = f"{tSDRG_path}/tSDRG/Main_15/data_random/BC_re/J_re/D_re/L_re_P_re_m_re_s_re/"
    # cpPathBase = f"{group_path}/tSDRG/Main_15/data_random/BC_re/J_re/D_re/L_re_P_re_m_re_s_re/"
    # targetPathBase = f"{group_path}/tSDRG/Main_15/data_collect/BC_re/J_re/D_re/L_re_P_re_m_re/"

    mySourcePath = mySourcePathBase.replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m)
    groupSourcePath = groupSourcePathBase.replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m)
    myTargetPath = myTargetPathBase.replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m)
    groupTargetPath = groupTargetPathBase.replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m)

    # cpPath = cpPathBase.replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m)
    # targetPath = targetPathBase.replace("BC_re", BC).replace("J_re", J).replace("D_re", D).replace("L_re", L).replace("P_re", P).replace("m_re", m)
    
    return (mySourcePath, groupSourcePath, myTargetPath, groupTargetPath)

def fread(f, phys):
    if os.path.exists(f):
        with open(f,"r") as a:
            a = a.readlines()
            if len(a) == 0:
                return 
            else:
                if phys in a[0].strip():
                    del a[0]
                a = "".join(a)
                a = a.replace("\n"," ")
                return a
    else:
        return 

def create_tarball_files(output_filename, file_list):
    with tarfile.open(output_filename, "w:gz") as tar:
        for file in file_list:
            tar.add(file, arcname=file)  # arcname ä¿æŒåŸå§‹æª”å
    print(f"å·²æ‰“åŒ… {len(file_list)} å€‹æª”æ¡ˆåˆ° {output_filename}")

def kill_files(file_list):
    for i,f in enumerate(file_list):
        os.system("rm " + f)
    return f"å·²åˆªé™¤ {len(file_list)} å€‹æª”æ¡ˆï¼Œå¾{file_list[0]}åˆ°{file_list[-1]}"
    
def cp_files(file_list):
    for i,f in enumerate(file_list):
        os.system("cp " + f)
    print(f"å·²è¤‡è£½ {len(file_list)} å€‹æª”æ¡ˆï¼Œå¾{file_list[0]}åˆ°{file_list[-1]}")



def parse_context(context):
    """
    å°‡åŸå§‹å­—ä¸²è§£æç‚ºéµå€¼å°åˆ—è¡¨ã€‚
    """
    lines = [line.strip() for line in context.strip().split('\n') if line.strip()]
    pairs = []
    for line in lines:
        if ':' in line:
            key_value = line.split(':', 1)
            if len(key_value) == 2:
                key_str, value = key_value
                try:
                    key_int = int(key_str.strip())
                    pairs.append((key_int, value.strip()))
                except ValueError:
                    continue
    return pairs

def is_sorted(pairs):
    """
    æª¢æŸ¥éµå€¼å°åˆ—è¡¨æ˜¯å¦å·²æŒ‰éµçš„å‡åºæ’åºã€‚
    """
    return all(pairs[i][0] <= pairs[i + 1][0] for i in range(len(pairs) - 1))

def sort_context(pairs):
    """
    å°éµå€¼å°åˆ—è¡¨æŒ‰éµé€²è¡Œæ’åºï¼Œä¸¦é‡å»ºç‚ºå­—ä¸²æ ¼å¼ã€‚
    """
    sorted_pairs = sorted(pairs, key=lambda x: x[0])
    s1 = sorted_pairs[0][0]  # å‡è¨­ç¬¬ä¸€å€‹éµæ˜¯ s1
    sorted_lines = [f"{key}:{value}" for key, value in sorted_pairs]
    return '\n'.join(sorted_lines), s1

def sort_if_needed(context):
    """
    è‹¥è³‡æ–™æœªæ’åºï¼Œå‰‡é€²è¡Œæ’åºï¼›å¦å‰‡è¿”å›åŸå§‹è³‡æ–™ã€‚
    """
    pairs = parse_context(context)
    if is_sorted(pairs):
        print("è³‡æ–™å·²æ’åºï¼Œç„¡éœ€æ’åºã€‚")
        s1 = int(pairs[0][0])  # å‡è¨­ç¬¬ä¸€å€‹éµæ˜¯ s1
        return context, s1
    else:
        print("è³‡æ–™æœªæ’åºï¼Œé–‹å§‹æ’åºã€‚")
        return sort_context(pairs)
        
def Combine(BC, J, D, L, P, m, phys, s1, s2):
    folder = creatDir(BC, J, D, L, P, m, phys)
    name = creatName(BC, J, D, L, P, m, phys)

    mySourcePath = folder[0] + "/" + name[0]
    groupSourcePath = folder[1] + "/" + name[1]
    myTarPath = folder[2] + "/" + name[2]
    groupTarPath = folder[3] + "/" + name[3]

    seedArray = list(range(s1, s2 + 1))
    # with open(groupTarPath, "r") as originFile:
    #     originaText = originFile.readlines()
    context = ""
    # print("originaText")
    for seed in seedArray:
        groupSource = groupSourcePath.replace("s_re", str(seed))
        mySource = mySourcePath.replace("s_re", str(seed))
        # if f"{seed}:" in originaText[seed-1]:
        #     continue
        if os.path.exists(groupSource) and os.path.exists(mySource):
            if compare(groupSource, mySource, seed):                
                fcontext = fread(mySource, phys)
            else:
                # os.remove(groupSource)
                shutil.copy(mySource, groupSource)
                fcontext = fread(groupSource, phys)
        elif os.path.exists(mySource):
            os.makedirs(os.path.dirname(groupSource), exist_ok=True)
            shutil.copy(mySource, groupSource)
            # os.remove(mySource)
            fcontext = fread(groupSource, phys)
        elif os.path.exists(groupSource):
            fcontext = fread(groupSource, phys)
        else:
            continue

        if fcontext is not None:
            context += f"{seed}:{fcontext}\n"

    if context != "":
        context, s1 = sort_if_needed(context)
        
        save_context(context, s1, groupTarPath, myTarPath, phys)
        # os.makedirs(os.path.dirname(myTarPath), exist_ok=True)
def save_context(context, s1, groupTarPath, myTarPath, phys):
    if not os.path.exists(groupTarPath):
        os.makedirs(os.path.dirname(groupTarPath), exist_ok=True)

    mode = "w" if s1 == 1 else "a"

    if s1 == 1:
        context = f"{phys}\n{context}"

    with open(groupTarPath, mode) as f1:
        try:
            # å˜—è©¦éé˜»å¡åŠ é–
            fcntl.flock(f1, fcntl.LOCK_EX | fcntl.LOCK_NB)
            print(f"âœ… ç«‹å³å–å¾—é– [PID {os.getpid()}] ({'WRITE' if s1==1 else 'APPEND'}): {groupTarPath}")
        except BlockingIOError:
            print(f"â³ é–ä½ç­‰å¾…ä¸­ [PID {os.getpid()}] â†’ {groupTarPath}")
            fcntl.flock(f1, fcntl.LOCK_EX)
            print(f"âœ… æœ€çµ‚å–å¾—é– [PID {os.getpid()}]")

        try:
            f1.write(context)
        finally:
            fcntl.flock(f1, fcntl.LOCK_UN)
            print(f"ğŸ”“ æª”æ¡ˆå·²è§£é– [PID {os.getpid()}] â†’ {groupTarPath}")
            
    # if phys == "ZL":
    #     save_ZL(BC, J, D, L, P, m, phys, groupTarPath)
    # elif phys == "energy":
    #     save_gap(BC, J, D, L, P, m, phys, groupTarPath)
    # elif phys == "corr1" or phys == "corr2":
    #     save_corr(BC, J, D, L, P, m, phys, groupTarPath)

# def save_context(context, s1, groupTarPath, myTarPath, phys):
#     if not os.path.exists(groupTarPath):
#         os.makedirs(os.path.dirname(groupTarPath), exist_ok=True)
#     if s1 == 1:
#         context = f"{phys}\n{context}"
#         # print(f"[WRITE] groupTarPath: {groupTarPath}, myTarPath: {myTarPath}")
#         with open(groupTarPath, "w") as f1:
            
#             try:
#                 # å˜—è©¦ç”¨éé˜»å¡æ–¹å¼åŠ é–
#                 fcntl.flock(f1, fcntl.LOCK_EX | fcntl.LOCK_NB)
#                 print("âœ… ç«‹å³å–å¾—é–")
#                 print(f"æª”æ¡ˆå·²é–å®š [WRITE] groupTarPath: {groupTarPath}, s1:{s1}, ç›®å‰é€²ç¨‹ PID: {os.getpid()}")
#                 f1.write(context)
#                 fcntl.flock(f1, fcntl.LOCK_EX | fcntl.LOCK_NB)
#                 print("âœ… æª”æ¡ˆå·²è§£é–")    
#             except BlockingIOError:
#                 print("â³ æª”æ¡ˆå·²è¢«é–ä½ï¼Œé€²å…¥ç­‰å¾…æ¨¡å¼...")
#                 fcntl.flock(f1, fcntl.LOCK_EX)  # é€™è£¡æ‰æœƒé˜»å¡ï¼Œç­‰é‡‹æ”¾
#                 print("âœ… æœ€çµ‚å–å¾—é–")
#                 print(f"æª”æ¡ˆå·²é–å®š [WRITE] groupTarPath: {groupTarPath}, s1:{s1}, ç›®å‰é€²ç¨‹ PID: {os.getpid()}")
#                 f1.write(context)
#                 fcntl.flock(f1, fcntl.LOCK_UN)
#                 print("âœ… æª”æ¡ˆå·²è§£é–")            # f2.write(context)
#         # with open(groupTarPath, "w") as f1, open(myTarPath, "w") as f2:
#         #     f1.write(context)
#         #     # f2.write(context)
#     else:
#         # print(f"[APPEND] groupTarPath: {groupTarPath}, myTarPath: {myTarPath}")
#         with open(groupTarPath, "a") as f1:
            
#             try:
#                 # å˜—è©¦ç”¨éé˜»å¡æ–¹å¼åŠ é–
#                 fcntl.flock(f1, fcntl.LOCK_EX | fcntl.LOCK_NB)
#                 print("âœ… ç«‹å³å–å¾—é–")
#                 print(f"æª”æ¡ˆå·²é–å®š [APPEND] groupTarPath: {groupTarPath}, s1:{s1}, ç›®å‰é€²ç¨‹ PID: {os.getpid()}")
#                 f1.write(context)
#                 fcntl.flock(f1, fcntl.LOCK_EX | fcntl.LOCK_NB)
#                 print("âœ… æª”æ¡ˆå·²è§£é–")    
#             except BlockingIOError:
#                 print("â³ æª”æ¡ˆå·²è¢«é–ä½ï¼Œé€²å…¥ç­‰å¾…æ¨¡å¼...")
#                 fcntl.flock(f1, fcntl.LOCK_EX)  # é€™è£¡æ‰æœƒé˜»å¡ï¼Œç­‰é‡‹æ”¾
#                 print("âœ… æœ€çµ‚å–å¾—é–")
#                 print(f"æª”æ¡ˆå·²é–å®š [APPEND] groupTarPath: {groupTarPath}, s1:{s1}, ç›®å‰é€²ç¨‹ PID: {os.getpid()}")
#                 f1.write(context)
#                 fcntl.flock(f1, fcntl.LOCK_UN)
#                 print("âœ… æª”æ¡ˆå·²è§£é–") 


        
def parameter_read_dict(filename):
    parameters = {}
    try:
        with open(filename, 'r', encoding='utf-8') as file:
            for line in file:
                if ':' in line:
                    key, value = line.split(':', 1)
                    key = key.strip()
                    value = value.strip()
                    if key:
                        parameters[key] = value
    except FileNotFoundError:
        print(f"ç„¡æ³•é–‹å•Ÿæª”æ¡ˆ: {filename}")
    
    return parameters


            
if __name__ == "__main__":
    file = sys.argv[1]
    arg = []
    # Jstr = [f"Jdis{str(i).zfill(3)}" for i in range(int(J),int(J)+1)]
    # Jstr = [f"Jdis{str(i).zfill(3)}" for i in range(30,81,50)]

    # Dstr = [f"Dim{str(i).zfill(3)}" for i in range(101)]
    # Lstr = [f"L{num}" for num in range(31, 255, 32)]  # åªæœ‰ L512
    # Lstr = [f"L{num}" for num in range(64, 129, 64)]  # åªæœ‰ L512
    a = scriptCreator.para("read",file)
    parameterlist = a.para
    para=scriptCreator.paraList1(parameterlist["L"],parameterlist["J"],parameterlist["D"],parameterlist["S"])
    BC = parameterlist["BC"]
    Pdis = parameterlist["Pdis"]
    chi = "m" + str(parameterlist["chi"])
    # s1 = int(parameterlist["S"]["S1"])
    # s2 = int(parameterlist["S"]["S2"])
    s1 = int(sys.argv[2])
    s2 = int(sys.argv[3])
    if BC == "PBC":
        s_list = ["ZL","corr1","corr2","string","J_list","energy","dimerization","w_loc","seed"]
    else:
        s_list = ["ZL","corr1","corr2","J_list","energy","dimerization","w_loc","seed"]
        
    for s in s_list:
        for L in para.L_str:
            for J in para.J_str:
                    arg.append((BC, J, para.D_str[0], L, f"P{Pdis}", f"{chi}", s, s1, s2))

    print(arg)         

    def fun(arg):
        print("---------------------col--------------------\n")
        with multiprocessing.Pool(processes=10) as pool:
            results1 = pool.starmap(Combine, arg)
        # print("---------------------del--------------------\n")
        # with multiprocessing.Pool(processes=20) as pool:
        #     results1 = pool.starmap(checkAndDelete, arg)
            
    # è¨ˆç®—å‡½æ•¸åŸ·è¡Œæ™‚é–“
    execution_time = timeit.timeit(lambda: fun(arg), number=1)

    # åŸ·è¡Œä¸¦é¡¯ç¤ºçµæœ
    # results1, results2 = fun(arg)
    print(f"Execution time: {execution_time} seconds")    
