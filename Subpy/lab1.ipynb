{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebc1aa9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('OBC', 'Jdis150', 'Dim000', 'L7', 'P10', 'm40', 'ZL', 1, 10000), ('OBC', 'Jdis150', 'Dim000', 'L7', 'P10', 'm40', 'corr1', 1, 10000), ('OBC', 'Jdis150', 'Dim000', 'L7', 'P10', 'm40', 'corr2', 1, 10000), ('OBC', 'Jdis150', 'Dim000', 'L7', 'P10', 'm40', 'string', 1, 10000), ('OBC', 'Jdis150', 'Dim000', 'L7', 'P10', 'm40', 'J_list', 1, 10000), ('OBC', 'Jdis150', 'Dim000', 'L7', 'P10', 'm40', 'energy', 1, 10000), ('OBC', 'Jdis150', 'Dim000', 'L7', 'P10', 'm40', 'dimerization', 1, 10000), ('OBC', 'Jdis150', 'Dim000', 'L7', 'P10', 'm40', 'w_loc', 1, 10000), ('OBC', 'Jdis150', 'Dim000', 'L7', 'P10', 'm40', 'seed', 1, 10000)]\n",
      "---------------------ave--------------------\n",
      "\n",
      "[('OBC', 'Jdis150', 'Dim000', 'L7', 'P10', 'm40', 'corr1', 1, 5)]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/dicos_ui_home/aronton/tSDRG_random/tSDRG/Main_15/data_collect/OBC/Jdis150/Dim000/L7_P10_m40/corr1_L7_P10_m40_Jdis150_Dim000.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/aronton/anaconda3/lib/python3.12/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"/home/aronton/anaconda3/lib/python3.12/multiprocessing/pool.py\", line 51, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_374737/3583248918.py\", line 458, in average\n    with open(myTarPath,\"r\") as a:\n         ^^^^^^^^^^^^^^^^^^^\n  File \"/home/aronton/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 324, in _modified_open\n    return io_open(file, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '/dicos_ui_home/aronton/tSDRG_random/tSDRG/Main_15/data_collect/OBC/Jdis150/Dim000/L7_P10_m40/corr1_L7_P10_m40_Jdis150_Dim000.txt'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 683\u001b[0m\n\u001b[1;32m    677\u001b[0m             pool\u001b[38;5;241m.\u001b[39mstarmap(average, arg)\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;66;03m# print(\"---------------------del--------------------\\n\")\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# with multiprocessing.Pool(processes=20) as pool:\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;66;03m#     results1 = pool.starmap(checkAndDelete, arg)\u001b[39;00m\n\u001b[1;32m    681\u001b[0m         \n\u001b[1;32m    682\u001b[0m \u001b[38;5;66;03m# 計算函數執行時間\u001b[39;00m\n\u001b[0;32m--> 683\u001b[0m execution_time \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mtimeit(\u001b[38;5;28;01mlambda\u001b[39;00m: fun(arg), number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    685\u001b[0m \u001b[38;5;66;03m# 執行並顯示結果\u001b[39;00m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;66;03m# results1, results2 = fun(arg)\u001b[39;00m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecution_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/timeit.py:237\u001b[0m, in \u001b[0;36mtimeit\u001b[0;34m(stmt, setup, timer, number, globals)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtimeit\u001b[39m(stmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass\u001b[39m\u001b[38;5;124m\"\u001b[39m, setup\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass\u001b[39m\u001b[38;5;124m\"\u001b[39m, timer\u001b[38;5;241m=\u001b[39mdefault_timer,\n\u001b[1;32m    235\u001b[0m            number\u001b[38;5;241m=\u001b[39mdefault_number, \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    236\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convenience function to create Timer object and call timeit method.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Timer(stmt, setup, timer, \u001b[38;5;28mglobals\u001b[39m)\u001b[38;5;241m.\u001b[39mtimeit(number)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/timeit.py:180\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    178\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 180\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minner(it, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimer)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<timeit-src>:6\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer, _stmt)\u001b[0m\n",
      "Cell \u001b[0;32mIn[17], line 683\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    677\u001b[0m             pool\u001b[38;5;241m.\u001b[39mstarmap(average, arg)\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;66;03m# print(\"---------------------del--------------------\\n\")\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# with multiprocessing.Pool(processes=20) as pool:\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;66;03m#     results1 = pool.starmap(checkAndDelete, arg)\u001b[39;00m\n\u001b[1;32m    681\u001b[0m         \n\u001b[1;32m    682\u001b[0m \u001b[38;5;66;03m# 計算函數執行時間\u001b[39;00m\n\u001b[0;32m--> 683\u001b[0m execution_time \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mtimeit(\u001b[38;5;28;01mlambda\u001b[39;00m: fun(arg), number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    685\u001b[0m \u001b[38;5;66;03m# 執行並顯示結果\u001b[39;00m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;66;03m# results1, results2 = fun(arg)\u001b[39;00m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecution_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 677\u001b[0m, in \u001b[0;36mfun\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28mprint\u001b[39m(arg)\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m multiprocessing\u001b[38;5;241m.\u001b[39mPool(processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m--> 677\u001b[0m         pool\u001b[38;5;241m.\u001b[39mstarmap(average, arg)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/pool.py:375\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_async(func, iterable, starmapstar, chunksize)\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/dicos_ui_home/aronton/tSDRG_random/tSDRG/Main_15/data_collect/OBC/Jdis150/Dim000/L7_P10_m40/corr1_L7_P10_m40_Jdis150_Dim000.txt'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import timeit\n",
    "import sys\n",
    "import tarfile\n",
    "import datetime\n",
    "import multiprocessing\n",
    "import scriptCreator\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tSDRG_path = \"/dicos_ui_home/aronton/tSDRG_random\"\n",
    "group_path = \"/ceph/work/NTHU-qubit/LYT/tSDRG_random\"\n",
    "\n",
    "    \n",
    "sourcelist = {\"ZL\":\"ZL.csv\", \"energy\":\"energy.csv\", \"seed\":\"s_re_seed.csv\",\\\n",
    "    \"corr1\":\"_\".join([\"L_re\",\"P_re\",\"m_re\",\"s_re\",\"corr1.csv\"]), \"corr2\":\"_\".join([\"L_re\",\"P_re\",\"m_re\",\"s_re\",\"corr2.csv\"]),\\\n",
    "    \"ZLI\":\"ZLI.csv\", \"ZLC\":\"ZLC.csv\", \"w_loc\":\"w_loc.csv\", \"J_list\":\"J_list.csv\", \"dimerization\":\"dimerization.csv\",\\\n",
    "    \"string\":\"_\".join([\"L_re\",\"P_re\",\"m_re\",\"s_re\",\"string.csv\"])\n",
    "    }\n",
    "\n",
    "grouplist = {\"ZL\":\"_\".join([\"L_re\",\"P_re\",\"m_re\",\"s_re\",\"ZL.txt\"]), \"energy\":\"_\".join([\"L_re\",\"P_re\",\"m_re\",\"s_re\",\"energy.txt\"]),\\\n",
    "    \"corr1\":\"_\".join([\"L_re\",\"P_re\",\"m_re\",\"s_re\",\"corr1.txt\"]), \"corr2\":\"_\".join([\"L_re\",\"P_re\",\"m_re\",\"s_re\",\"corr2.txt\"]),\\\n",
    "    \"ZLI\":\"_\".join([\"L_re\",\"P_re\",\"m_re\",\"s_re\",\"ZLI.txt\"]), \"ZLC\":\"_\".join([\"L_re\",\"P_re\",\"m_re\",\"s_re\",\"ZLC.txt\"]),\\\n",
    "    \"w_loc\":\"_\".join([\"L_re\",\"P_re\",\"m_re\",\"s_re\",\"w_loc.txt\"]), \"J_list\":\"_\".join([\"L_re\",\"P_re\",\"m_re\",\"s_re\",\"J_list.txt\"]),\\\n",
    "    \"string\":\"_\".join([\"L_re\",\"P_re\",\"m_re\",\"s_re\",\"string.txt\"]), \"seed\":\"_\".join([\"L_re\",\"P_re\",\"m_re\",\"s_re\",\"seed.txt\"]),\\\n",
    "    \"dimerization\":\"_\".join([\"L_re\",\"P_re\",\"m_re\",\"s_re\",\"dimerization.txt\"])\n",
    "    }\n",
    "\n",
    "tarlist = {\n",
    "    \"ZL\":\"_\".join([\"ZL\",\"L_re\",\"P_re\",\"m_re\",\"J_re\",\"D_re.txt\"]),\\\n",
    "    \"energy\":\"_\".join([\"energy\",\"L_re\",\"P_re\",\"m_re\",\"J_re\",\"D_re.txt\"]),\\\n",
    "    \"corr1\":\"_\".join([\"corr1\",\"L_re\",\"P_re\",\"m_re\",\"J_re\",\"D_re.txt\"]),\\\n",
    "    \"corr2\":\"_\".join([\"corr2\",\"L_re\",\"P_re\",\"m_re\",\"J_re\",\"D_re.txt\"]),\\\n",
    "    \"ZLI\":\"_\".join([\"ZLI\",\"L_re\",\"P_re\",\"m_re\",\"J_re\",\"D_re.txt\"]),\\\n",
    "    \"ZLC\":\"_\".join([\"ZLC\",\"L_re\",\"P_re\",\"m_re\",\"J_re\",\"D_re.txt\"]),\\\n",
    "    \"w_loc\":\"_\".join([\"w_loc\",\"L_re\",\"P_re\",\"m_re\",\"J_re\",\"D_re.txt\"]),\\\n",
    "    \"J_list\":\"_\".join([\"J_list\",\"L_re\",\"P_re\",\"m_re\",\"J_re\",\"D_re.txt\"]),\\\n",
    "    \"string\":\"_\".join([\"string\",\"L_re\",\"P_re\",\"m_re\",\"J_re\",\"D_re.txt\"]),\\\n",
    "    \"seed\":\"_\".join([\"seed\",\"L_re\",\"P_re\",\"m_re.txt\"]),\n",
    "    \"dimerization\":\"_\".join([\"dimerization\",\"L_re\",\"P_re\",\"m_re.txt\"])\n",
    "    }\n",
    "\n",
    "\n",
    "# collist = {\n",
    "#     \"ZL\":\"_\".join([\"ZL\",\"L_re\",\"P_re\",\"m_re\",\"J_re\",\"D_re\",\"s_re.txt\"]),\\\n",
    "#     \"energy\":\"_\".join([\"energy\",\"L_re\",\"P_re\",\"m_re\",\"J_re\",\"D_re\",\"s_re.txt\"]),\\\n",
    "#     \"corr1\":\"_\".join([\"corr1\",\"L_re\",\"P_re\",\"m_re\",\"J_re\",\"D_re\",\"s_re.txt\"]),\\\n",
    "#     \"corr2\":\"_\".join([\"corr2\",\"L_re\",\"P_re\",\"m_re\",\"J_re\",\"D_re\",\"s_re.txt\"]),\\\n",
    "#     \"ZLI\":\"_\".join([\"ZLI\",\"L_re\",\"P_re\",\"m_re\",\"J_re\",\"D_re\",\"s_re.txt\"]),\\\n",
    "#     \"ZLC\":\"_\".join([\"ZLC\",\"L_re\",\"P_re\",\"m_re\",\"J_re\",\"D_re\",\"s_re.txt\"]),\\\n",
    "#     \"w_loc\":\"_\".join([\"w_loc\",\"L_re\",\"P_re\",\"m_re\",\"J_re\",\"D_re\",\"s_re.txt\"]),\\\n",
    "#     \"J_list\":\"_\".join([\"J_list\",\"L_re\",\"P_re\",\"m_re\",\"J_re\",\"D_re\",\"s_re.txt\"]),\\\n",
    "#     \"string\":\"_\".join([\"string\",\"L_re\",\"P_re\",\"m_re\",\"J_re\",\"D_re\",\"s_re.txt\"]),\\\n",
    "#     \"seed\":\"_\".join([\"seed\",\"L_re\",\"P_re\",\"m_re\",\"s_re.txt\"]),\n",
    "#     \"dimerization\":\"_\".join([\"dimerization\",\"L_re\",\"P_re\",\"m_re\",\"s_re.txt\"])\n",
    "#     }\n",
    "\n",
    "def parameterRead(filePath):\n",
    "    with open(filePath,\"r\") as a:\n",
    "        a = a.readlines()    \n",
    "        for i,v in enumerate(a):\n",
    "            key = v.split(\":\")[0]\n",
    "            value = v.split(\":\")[1]\n",
    "            if key in paralist:\n",
    "                paralist[key] = value \n",
    "            \n",
    "\n",
    "def checkInside(s, f, sample, phys):\n",
    "    with open(f,\"r\") as a:\n",
    "        a = a.readlines()    \n",
    "        if a[0].strip() == phys:\n",
    "            del a[0]\n",
    "        data = [(v.split(\":\")[0].strip(),(v.split(\":\")[1].replace(\"\\n\",\" \").strip())) for i,v in enumerate(a)]\n",
    "        sorted_data = sorted(data, key=lambda x: int(x[0]))\n",
    "    if s == sorted_data[sample+1][1]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def compare(f1,f2,sample):\n",
    "    with open(f1,\"r\") as a:\n",
    "        a = a.readlines()\n",
    "    with open(f2,\"r\") as b:\n",
    "        b = b.readlines()\n",
    "    if (len(a) <= 2) and (len(b) <=2 ):\n",
    "        return (a == b)\n",
    "    elif (len(a) > 2) and (len(b) > 2 ):\n",
    "        return (a == b)\n",
    "    elif (len(a) <= 2) and (len(b) > 2 ):\n",
    "        if len(a) == 2:\n",
    "            del a[0]\n",
    "            data1 = a[0].strip()\n",
    "            # print(data1)\n",
    "        else:\n",
    "            data1 = a[0].strip()\n",
    "            # print(data1)\n",
    "        del b[0]\n",
    "        \n",
    "        for i,v in enumerate(b):\n",
    "            # print(v.split(\":\")[0])\n",
    "            # print(v.split(\":\")[1])\n",
    "            if data1 in v.strip():\n",
    "                if v.split(\":\")[0] == sample:\n",
    "                    return True\n",
    "        return False\n",
    "    elif (len(a) > 2) and (len(b) < 2 ):\n",
    "        if len(b) == 2:\n",
    "            del b[0]\n",
    "            data1 = b[0].strip()\n",
    "        else:\n",
    "            data1 = b[0].strip()\n",
    "        del a[0]\n",
    "        for i,v in enumerate(a):\n",
    "            if data1 in v.strip():\n",
    "                if v.split(\":\")[0] == sample:\n",
    "                    return True\n",
    "        return False\n",
    "def checkFileNum(dirpath):\n",
    "    folder = Path(dirpath) \n",
    "    file_count = sum(1 for f in folder.iterdir() if f.is_file())\n",
    "    return file_count\n",
    "\n",
    "def creatName(BC, J, D, L, P, m, phys):\n",
    "    mySourceName = sourcelist[phys].replace(\"BC_re\", BC).replace(\"J_re\", J).replace(\"D_re\", D).replace(\"L_re\", L).replace(\"P_re\", P).replace(\"m_re\", m) \n",
    "    myTargetName = tarlist[phys].replace(\"BC_re\", BC).replace(\"J_re\", J).replace(\"D_re\", D).replace(\"L_re\", L).replace(\"P_re\", P).replace(\"m_re\", m) \n",
    "    groupSourceName = grouplist[phys].replace(\"BC_re\", BC).replace(\"J_re\", J).replace(\"D_re\", D).replace(\"L_re\", L).replace(\"P_re\", P).replace(\"m_re\", m) \n",
    "    groupTargetName = tarlist[phys].replace(\"BC_re\", BC).replace(\"J_re\", J).replace(\"D_re\", D).replace(\"L_re\", L).replace(\"P_re\", P).replace(\"m_re\", m) \n",
    "    return (mySourceName, groupSourceName, myTargetName, groupTargetName)\n",
    "\n",
    "def creatCpName(BC, J, D, L, P, m, phys):\n",
    "    CpName = newlist[phys].replace(\"BC_re\", BC).replace(\"J_re\", J).replace(\"D_re\", D).replace(\"L_re\", L).replace(\"P_re\", P).replace(\"m_re\", m) \n",
    "    return CpName\n",
    "def creatColName(BC, J, D, L, P, m, phys):\n",
    "    colName = collist[phys].replace(\"BC_re\", BC).replace(\"J_re\", J).replace(\"D_re\", D).replace(\"L_re\", L).replace(\"P_re\", P).replace(\"m_re\", m) \n",
    "    return colName\n",
    "def creatMetaName(BC, J, D, L, P, m, phys):\n",
    "    metaName = tarlist[phys].replace(\"BC_re\", BC).replace(\"J_re\", J).replace(\"D_re\", D).replace(\"L_re\", L).replace(\"P_re\", P).replace(\"m_re\", m) \n",
    "    return colName\n",
    "def creatDir(BC, J, D, L, P, m, phys):\n",
    "    sourcePath = \"/\".join([\"tSDRG\",\"Main_15\",\"data_random\",\"BC_re\",\"J_re\",\"D_re\",\"L_re_P_re_m_re_s_re\"])\n",
    "    tarPath = \"/\".join([\"tSDRG\",\"Main_15\",\"data_collect\",\"BC_re\",\"J_re\",\"D_re\",\"L_re_P_re_m_re\"])\n",
    "    metaPath = \"/\".join([\"tSDRG\",\"Main_15\",\"metadata\",\"BC_re\",\"J_re\",\"D_re\",\"L_re_P_re_m_re\"])\n",
    "    mySourcePathBase = \"/\".join([tSDRG_path,sourcePath])\n",
    "    groupSourcePathBase = \"/\".join([group_path,sourcePath])\n",
    "    myTargetPathBase = \"/\".join([tSDRG_path,tarPath])\n",
    "    groupTargetPathBase = \"/\".join([group_path,tarPath])\n",
    "    myMetaPathBase = \"/\".join([tSDRG_path,metaPath])\n",
    "    groupMetaPathBase = \"/\".join([group_path,metaPath])\n",
    "    # sourcePathBase = f\"{tSDRG_path}/tSDRG/Main_15/data_random/BC_re/J_re/D_re/L_re_P_re_m_re_s_re/\"\n",
    "    # cpPathBase = f\"{group_path}/tSDRG/Main_15/data_random/BC_re/J_re/D_re/L_re_P_re_m_re_s_re/\"\n",
    "    # targetPathBase = f\"{group_path}/tSDRG/Main_15/data_collect/BC_re/J_re/D_re/L_re_P_re_m_re/\"\n",
    "\n",
    "    mySourcePath = mySourcePathBase.replace(\"BC_re\", BC).replace(\"J_re\", J).replace(\"D_re\", D).replace(\"L_re\", L).replace(\"P_re\", P).replace(\"m_re\", m)\n",
    "    groupSourcePath = groupSourcePathBase.replace(\"BC_re\", BC).replace(\"J_re\", J).replace(\"D_re\", D).replace(\"L_re\", L).replace(\"P_re\", P).replace(\"m_re\", m)\n",
    "    myTargetPath = myTargetPathBase.replace(\"BC_re\", BC).replace(\"J_re\", J).replace(\"D_re\", D).replace(\"L_re\", L).replace(\"P_re\", P).replace(\"m_re\", m)\n",
    "    groupTargetPath = groupTargetPathBase.replace(\"BC_re\", BC).replace(\"J_re\", J).replace(\"D_re\", D).replace(\"L_re\", L).replace(\"P_re\", P).replace(\"m_re\", m)\n",
    "    myMetaPath = myMetaPathBase.replace(\"BC_re\", BC).replace(\"J_re\", J).replace(\"D_re\", D).replace(\"L_re\", L).replace(\"P_re\", P).replace(\"m_re\", m)\n",
    "    groupMetaPath = groupMetaPathBase.replace(\"BC_re\", BC).replace(\"J_re\", J).replace(\"D_re\", D).replace(\"L_re\", L).replace(\"P_re\", P).replace(\"m_re\", m)\n",
    "    # cpPath = cpPathBase.replace(\"BC_re\", BC).replace(\"J_re\", J).replace(\"D_re\", D).replace(\"L_re\", L).replace(\"P_re\", P).replace(\"m_re\", m)\n",
    "    # targetPath = targetPathBase.replace(\"BC_re\", BC).replace(\"J_re\", J).replace(\"D_re\", D).replace(\"L_re\", L).replace(\"P_re\", P).replace(\"m_re\", m)\n",
    "    \n",
    "    return (mySourcePath, groupSourcePath, myTargetPath, groupTargetPath, myMetaPath, groupMetaPath)\n",
    "\n",
    "def fread(f, phys):\n",
    "    if os.path.exists(f):\n",
    "        with open(f,\"r\") as a:\n",
    "            a = a.readlines()\n",
    "            if len(a) == 0:\n",
    "                return \n",
    "            else:\n",
    "                if phys in a[0].strip():\n",
    "                    del a[0]\n",
    "                a = \"\".join(a)\n",
    "                a = a.replace(\"\\n\",\" \")\n",
    "                return a\n",
    "    else:\n",
    "        return \n",
    "\n",
    "def create_tarball_files(output_filename, file_list):\n",
    "    with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "        for file in file_list:\n",
    "            tar.add(file, arcname=file)  # arcname 保持原始檔名\n",
    "    print(f\"已打包 {len(file_list)} 個檔案到 {output_filename}\")\n",
    "\n",
    "def kill_files(file_list):\n",
    "    for i,f in enumerate(file_list):\n",
    "        os.system(\"rm \" + f)\n",
    "    return f\"已刪除 {len(file_list)} 個檔案，從{file_list[0]}到{file_list[-1]}\"\n",
    "    \n",
    "def cp_files(file_list):\n",
    "    for i,f in enumerate(file_list):\n",
    "        os.system(\"cp \" + f)\n",
    "    print(f\"已複製 {len(file_list)} 個檔案，從{file_list[0]}到{file_list[-1]}\")\n",
    "\n",
    "\n",
    "def ZLAverage(BC, J, D, L, P, m, phys):\n",
    "    folder = creatDir(BC, J, D, L, P, m, phys)\n",
    "    sourceName = creatCpName(BC, J, D, L, P, m, phys)\n",
    "    colName = creatColName(BC, J, D, L, P, m, phys)\n",
    "    source += folder[0] + source\n",
    "    collect += folder[1] + collect\n",
    "    \n",
    "    with open(collect, \"a\") as targetFile:\n",
    "        \n",
    "        for seed in  seedArray:\n",
    "            sourcePath = source.replace(\"s_re\",str(seed))\n",
    "            if os.path_exist(sourcePath):\n",
    "                context += fread(source,\"ZL\") + \"\\n\"\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "# def Combine(BC, J, D, L, P, m, phys, s1, s2):\n",
    "#     folder = creatDir(BC, J, D, L, P, m, phys)\n",
    "#     name = creatName(BC, J, D, L, P, m, phys)\n",
    "\n",
    "#     mySourcePath = folder[0] + \"/\" + name[0]\n",
    "#     groupSourcePath = folder[1] + \"/\" + name[1]\n",
    "#     myTarPath = folder[2] + \"/\" + name[2]\n",
    "#     groupTarPath = folder[3] + \"/\" + name[3]\n",
    "\n",
    "#     seedArray = list(range(s1, s2 + 1))\n",
    "#     context = \"\"\n",
    "\n",
    "#     for seed in seedArray:\n",
    "#         groupSource = groupSourcePath.replace(\"s_re\", str(seed))\n",
    "#         mySource = mySourcePath.replace(\"s_re\", str(seed))\n",
    "\n",
    "#         if os.path.exists(groupSource) and os.path.exists(mySource):\n",
    "#             if compare(groupSource, mySource, seed):\n",
    "#                 fcontext = fread(groupSource, phys)\n",
    "#             else:\n",
    "#                 os.remove(groupSource)\n",
    "#                 shutil.copy(mySource, groupSource)\n",
    "#                 fcontext = fread(groupSource, phys)\n",
    "#         elif os.path.exists(mySource):\n",
    "#             os.makedirs(os.path.dirname(groupSource), exist_ok=True)\n",
    "#             shutil.copy(mySource, groupSource)\n",
    "#             os.remove(mySource)\n",
    "#             fcontext = fread(groupSource, phys)\n",
    "#         elif os.path.exists(groupSource):\n",
    "#             fcontext = fread(groupSource, phys)\n",
    "#         else:\n",
    "#             continue\n",
    "\n",
    "#         if fcontext is not None:\n",
    "#             context += f\"{seed}:{fcontext}\\n\"\n",
    "\n",
    "#     if context != \"\":\n",
    "#         os.makedirs(os.path.dirname(groupTarPath), exist_ok=True)\n",
    "#         os.makedirs(os.path.dirname(myTarPath), exist_ok=True)\n",
    "\n",
    "#         if s1 == 1:\n",
    "#             context = f\"{phys}\\n{context}\"\n",
    "#             print(f\"[WRITE] groupTarPath: {groupTarPath}, myTarPath: {myTarPath}\")\n",
    "#             with open(groupTarPath, \"w\") as f1, open(myTarPath, \"w\") as f2:\n",
    "#                 f1.write(context)\n",
    "#                 f2.write(context)\n",
    "#         else:\n",
    "#             print(f\"[APPEND] groupTarPath: {groupTarPath}, myTarPath: {myTarPath}\")\n",
    "#             with open(groupTarPath, \"a\") as f1, open(myTarPath, \"a\") as f2:\n",
    "#                 f1.write(context)\n",
    "#                 f2.write(context)            \n",
    "\n",
    "def parse_context(context):\n",
    "    \"\"\"\n",
    "    將原始字串解析為鍵值對列表。\n",
    "    \"\"\"\n",
    "    lines = [line.strip() for line in context.strip().split('\\n') if line.strip()]\n",
    "    pairs = []\n",
    "    for line in lines:\n",
    "        if ':' in line:\n",
    "            key_value = line.split(':', 1)\n",
    "            if len(key_value) == 2:\n",
    "                key_str, value = key_value\n",
    "                try:\n",
    "                    key_int = int(key_str.strip())\n",
    "                    pairs.append((key_int, value.strip()))\n",
    "                except ValueError:\n",
    "                    continue\n",
    "    return pairs\n",
    "\n",
    "def is_sorted(pairs):\n",
    "    \"\"\"\n",
    "    檢查鍵值對列表是否已按鍵的升序排序。\n",
    "    \"\"\"\n",
    "    return all(pairs[i][0] <= pairs[i + 1][0] for i in range(len(pairs) - 1))\n",
    "\n",
    "def sort_context(pairs):\n",
    "    \"\"\"\n",
    "    對鍵值對列表按鍵進行排序，並重建為字串格式。\n",
    "    \"\"\"\n",
    "    sorted_pairs = sorted(pairs, key=lambda x: x[0])\n",
    "    s1 = sorted_pairs[0][0]  # 假設第一個鍵是 s1\n",
    "    sorted_lines = [f\"{key}:{value}\" for key, value in sorted_pairs]\n",
    "    return '\\n'.join(sorted_lines), s1\n",
    "\n",
    "def sort_if_needed(context):\n",
    "    \"\"\"\n",
    "    若資料未排序，則進行排序；否則返回原始資料。\n",
    "    \"\"\"\n",
    "    pairs = parse_context(context)\n",
    "    if is_sorted(pairs):\n",
    "        print(\"資料已排序，無需排序。\")\n",
    "        s1 = int(pairs[0][0])  # 假設第一個鍵是 s1\n",
    "        return context, s1\n",
    "    else:\n",
    "        print(\"資料未排序，開始排序。\")\n",
    "        return sort_context(pairs)\n",
    "        \n",
    "def Combine(BC, J, D, L, P, m, phys, s1, s2):\n",
    "    folder = creatDir(BC, J, D, L, P, m, phys)\n",
    "    name = creatName(BC, J, D, L, P, m, phys)\n",
    "\n",
    "    mySourcePath = folder[0] + \"/\" + name[0]\n",
    "    groupSourcePath = folder[1] + \"/\" + name[1]\n",
    "    myTarPath = folder[2] + \"/\" + name[2]\n",
    "    groupTarPath = folder[3] + \"/\" + name[3]\n",
    "\n",
    "    seedArray = list(range(s1, s2 + 1))\n",
    "    context = \"\"\n",
    "\n",
    "    for seed in seedArray:\n",
    "        groupSource = groupSourcePath.replace(\"s_re\", str(seed))\n",
    "        mySource = mySourcePath.replace(\"s_re\", str(seed))\n",
    "\n",
    "        if os.path.exists(groupSource) and os.path.exists(mySource):\n",
    "            if compare(groupSource, mySource, seed):\n",
    "                fcontext = fread(mySource, phys)\n",
    "            else:\n",
    "                os.remove(groupSource)\n",
    "                shutil.copy(mySource, groupSource)\n",
    "                fcontext = fread(groupSource, phys)\n",
    "        elif os.path.exists(mySource):\n",
    "            os.makedirs(os.path.dirname(groupSource), exist_ok=True)\n",
    "            shutil.copy(mySource, groupSource)\n",
    "            os.remove(mySource)\n",
    "            fcontext = fread(groupSource, phys)\n",
    "        elif os.path.exists(groupSource):\n",
    "            fcontext = fread(groupSource, phys)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if fcontext is not None:\n",
    "            context += f\"{seed}:{fcontext}\\n\"\n",
    "\n",
    "    if context != \"\":\n",
    "        context, s1 = sort_if_needed(context)\n",
    "        os.makedirs(os.path.dirname(groupTarPath), exist_ok=True)\n",
    "        save_context(context, s1, groupTarPath, myTarPath, phys)\n",
    "        # os.makedirs(os.path.dirname(myTarPath), exist_ok=True)\n",
    "\n",
    "\n",
    "def save_context(context, s1, groupTarPath, myTarPath, phys):\n",
    "        if s1 == 1:\n",
    "            context = f\"{phys}\\n{context}\"\n",
    "            print(f\"[WRITE] groupTarPath: {groupTarPath}, myTarPath: {myTarPath}\")\n",
    "            with open(groupTarPath, \"w\") as f1:\n",
    "                f1.write(context)\n",
    "                # f2.write(context)\n",
    "            # with open(groupTarPath, \"w\") as f1, open(myTarPath, \"w\") as f2:\n",
    "            #     f1.write(context)\n",
    "            #     # f2.write(context)\n",
    "        else:\n",
    "            print(f\"[APPEND] groupTarPath: {groupTarPath}, myTarPath: {myTarPath}\")\n",
    "            with open(groupTarPath, \"a\") as f1:\n",
    "                f1.write(context)\n",
    "                # f2.write(context)         \n",
    "            # with open(groupTarPath, \"a\") as f1, open(myTarPath, \"a\") as f2:\n",
    "            #     f1.write(context)\n",
    "            #     # f2.write(context)       \n",
    "\n",
    "def average2(BC, J, D, L, P, m, phys, s1, s2):\n",
    "    folder = creatDir(BC, J, D, L, P, m, phys)\n",
    "    name = creatName(BC, J, D, L, P, m, phys)\n",
    "\n",
    "    mySourcePath = folder[0] + \"/\" + name[0]\n",
    "    groupSourcePath = folder[1] + \"/\" + name[1]\n",
    "    myTarPath = folder[2] + \"/\" + name[2]\n",
    "    groupTarPath = folder[3] + \"/\" + name[3]\n",
    "\n",
    "    # 讀取檔案內容\n",
    "    with open(myTarPath, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # 如果第一行包含物理量名稱就刪除\n",
    "    if phys in lines[0].strip():\n",
    "        lines = lines[1:]\n",
    "\n",
    "    metaContext = {}\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # e.g., \"12: 0-1:0.123 1-2:0.456 ...\"\n",
    "        parts = line.split(\":\")\n",
    "        if len(parts) < 2:\n",
    "            continue\n",
    "\n",
    "        sNum = int(parts[0])  # 例如樣本編號\n",
    "\n",
    "        if sNum not in metaContext:\n",
    "            metaContext[sNum] = {}\n",
    "\n",
    "        # 拿掉樣本編號後的部分，拆分為多個 \"i-j:value\"\n",
    "        correlations = parts[1].strip().split()\n",
    "        for corr in correlations:\n",
    "            try:\n",
    "                pair, val = corr.split(\":\")\n",
    "                i, j = map(int, pair.split(\"-\"))\n",
    "                dx = abs(j - i)\n",
    "                val = float(val)\n",
    "            except:\n",
    "                continue  # 若格式不符則略過此項\n",
    "\n",
    "            if dx not in metaContext[sNum]:\n",
    "                metaContext[sNum][dx] = []\n",
    "            metaContext[sNum][dx].append(val)\n",
    "\n",
    "    # 整理平均值、誤差、樣本數\n",
    "    for sNum, dx_dict in metaContext.items():\n",
    "        for dx, values in dx_dict.items():\n",
    "            avg = np.mean(values)\n",
    "            std = np.std(values, ddof=1) if len(values) > 1 else 0.0\n",
    "            count = len(values)\n",
    "            dx_dict[dx] = [f\"corrAve:{avg}\", f\"error:{std}\", f\"sample:{count}\"]\n",
    "\n",
    "    # 輸出字串格式\n",
    "    context = \"\"\n",
    "    for sNum in sorted(metaContext.keys()):\n",
    "        context += f\"{sNum}:\"\n",
    "        for dx in sorted(metaContext[sNum].keys()):\n",
    "            corr_info = \",\".join(metaContext[sNum][dx])\n",
    "            context += f\"{dx}:{corr_info};\"\n",
    "        context += \"\\n\"\n",
    "\n",
    "    # 寫入 ./meta\n",
    "    os.makedirs(\"./meta\", exist_ok=True)\n",
    "    with open(\"./meta/meta_output.txt\", \"w\") as meta:\n",
    "        meta.write(context)\n",
    "\n",
    "def average(BC, J, D, L, P, m, phys, s1, s2):\n",
    "    folder = creatDir(BC, J, D, L, P, m, phys)\n",
    "    name = creatName(BC, J, D, L, P, m, phys)\n",
    "\n",
    "    mySourcePath = folder[0] + \"/\" + name[0]\n",
    "    groupSourcePath = folder[1] + \"/\" + name[1]\n",
    "    myTarPath = folder[2] + \"/\" + name[2]\n",
    "    groupTarPath = folder[3] + \"/\" + name[3]\n",
    "    myMetaPath = folder[4] + \"/\" + name[2]\n",
    "    groupMetaPath = folder[5] + \"/\" + name[3]\n",
    "    with open(myTarPath,\"r\") as a:\n",
    "        a = a.readlines()\n",
    "        if phys in a[0].strip():\n",
    "            del a[0]\n",
    "        metaContext = {}\n",
    "        for i,s in enumerate(a):\n",
    "            if i == s2:\n",
    "                break\n",
    "            s = s.strip()\n",
    "            sNum = int(s[0])\n",
    "            if sNum not in metaContext:\n",
    "                metaContext[sNum] = {}\n",
    "            print(f\"sNum:{sNum}\")\n",
    "            s = s.split(\" \")    \n",
    "            del s[0]\n",
    "            \n",
    "            for corr in s:\n",
    "                corr = corr.split(\",\")\n",
    "                if int(corr[1]) - int(corr[0]) not in metaContext[sNum]:\n",
    "                    metaContext[sNum][int(corr[1]) - int(corr[0])] = [float(corr[2])]\n",
    "                else:\n",
    "                    metaContext[sNum][int(corr[1]) - int(corr[0])].append(float(corr[2]))\n",
    "            for key, value in metaContext[sNum].items():\n",
    "                print(f\"key:{key},value:{value}\")\n",
    "                if len(value) == 0:\n",
    "                    continue\n",
    "                # print(f\"mean:{np.mean(value)}\")\n",
    "                # print(f\"std:{np.std(value, ddof=1)}\")\n",
    "                metaContext[sNum][key] = [f\"corrAve:{np.mean(value)}\", f\"error:{np.std(value, ddof=1)}\", f\"sample:{len(value)}\" ]\n",
    "        context = \"\"\n",
    "        \n",
    "        for num, value in metaContext.items():\n",
    "            context += f\"{num}:\"\n",
    "            for dx, corr in value.items():\n",
    "                context += f\"{dx}:\" + \",\".join(str(c) for c in corr) + \";\"\n",
    "            context += \"\\n\"\n",
    "        # print(f\"context{context}\")\n",
    "\n",
    "        os.makedirs(os.path.dirname(myMetaPath), exist_ok=True)\n",
    "        os.makedirs(os.path.dirname(groupMetaPath), exist_ok=True)\n",
    "        with open(myMetaPath, \"w\") as myMetaPath:\n",
    "            myMetaPath.write(context)\n",
    "        with open(groupMetaPath, \"w\") as groupMetaPath:\n",
    "            groupMetaPath.write(context)            \n",
    "def Combine1(BC, J, D, L, P, m, phys, s1, s2):\n",
    "    folder = creatDir(BC, J, D, L, P, m, phys)\n",
    "    name = creatName(BC, J, D, L, P, m, phys)\n",
    "\n",
    "    mySourcePath = folder[0] + \"/\" + name[0]\n",
    "    groupSourcePath = folder[1] + \"/\" + name[1]\n",
    "    myTarPath = folder[2] + \"/\" + name[2]\n",
    "    groupTarPath = folder[3] + \"/\" + name[3]\n",
    "\n",
    "    seedArray = list(range(s1,s2+1))\n",
    "    \n",
    "    context = \"\"\n",
    "    \n",
    "    for seed in  seedArray:\n",
    "        groupSource = groupSourcePath.replace(\"s_re\",str(seed))\n",
    "        mySource = mySourcePath.replace(\"s_re\",str(seed))\n",
    "\n",
    "        if os.path.exists(groupSource) and os.path.exists(mySource):\n",
    "            if compare(groupSource, mySource, seed):\n",
    "                fcontext = fread(groupSource,phys)\n",
    "                if fcontext == None:\n",
    "                    continue\n",
    "                context += f\"{seed}:{fcontext}\\n\"\n",
    "            else:\n",
    "                os.remove(groupSource)\n",
    "                shutil.copy(mySource, groupSource)\n",
    "                fcontext = fread(groupSource,phys)\n",
    "                if fcontext == None:\n",
    "                    continue\n",
    "                context += f\"{seed}:{fcontext}\\n\"\n",
    "        else:\n",
    "            if os.path.exists(mySource):\n",
    "                os.makedirs(os.path.dirname(groupSource), exist_ok=True)\n",
    "                shutil.copy(mySource, groupSource)\n",
    "                os.remove(mySource)\n",
    "                fcontext = fread(groupSource,phys)\n",
    "                if fcontext == None:\n",
    "                    continue\n",
    "                context += f\"{seed}:{fcontext}\\n\"\n",
    "            else:\n",
    "                fcontext = fread(groupSource,phys)\n",
    "                if fcontext == None:\n",
    "                    continue\n",
    "                context += f\"{seed}:{fcontext}\\n\"              \n",
    "\n",
    "    if context != \"\":\n",
    "        if s1 == 1:\n",
    "            context = f\"{phys}\\n{context}\" \n",
    "            print(f\"groupTarPath:{groupTarPath}, myTarPath:{myTarPath}\")\n",
    "            os.makedirs(os.path.dirname(groupTarPath), exist_ok=True)\n",
    "            os.makedirs(os.path.dirname(myTarPath), exist_ok=True)\n",
    "            with open(groupTarPath, \"w\") as targetFile1, open(myTarPath, 'w') as targetFile2:\n",
    "                targetFile1.write(context)\n",
    "                targetFile2.write(context)\n",
    "        else:\n",
    "            if os.path.exits(groupTarPath) and os.path.exits(myTarPath):\n",
    "                print(f\"groupTarPath:{groupTarPath}, myTarPath:{myTarPath}\")\n",
    "                os.makedirs(os.path.dirname(groupTarPath), exist_ok=True)\n",
    "                os.makedirs(os.path.dirname(myTarPath), exist_ok=True)\n",
    "                with open(groupTarPath, \"a\") as targetFile1, open(myTarPath, 'a') as targetFile2:\n",
    "                    targetFile1.write(context)\n",
    "                    targetFile2.write(context)   \n",
    "            else:\n",
    "                print(f\"groupTarPath or myTarPath not exist\")   \n",
    "\n",
    "def parameter_read_dict(filename):\n",
    "    parameters = {}\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                if ':' in line:\n",
    "                    key, value = line.split(':', 1)\n",
    "                    key = key.strip()\n",
    "                    value = value.strip()\n",
    "                    if key:\n",
    "                        parameters[key] = value\n",
    "    except FileNotFoundError:\n",
    "        print(f\"無法開啟檔案: {filename}\")\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "# def corrAverage(BC, J, D, L, P, m, phys):\n",
    "#     folder = creatDir()\n",
    "#     source = creatCpName()\n",
    "#     collect = creatColName()\n",
    "#     source += folder + source\n",
    "#     collect += folder + collect\n",
    "    \n",
    "#     with open(collect, \"a\") as targetFile:\n",
    "        \n",
    "#         for seed in  seedArray:\n",
    "#             sourcePath = source.replace(\"s_re\",str(seed))\n",
    "#             if os.path_exist(sourcePath):\n",
    "#                 context += fread(source,\"ZL\") + \"\\n\"\n",
    "#             else\n",
    "#                 continue\n",
    "def gapAverage(BC, J, D, L, P, m, phys):\n",
    "    folder = creatDir()\n",
    "    source = creatCpName()\n",
    "    collect = creatColName()\n",
    "    source += folder + source\n",
    "    collect += folder + collect\n",
    "    \n",
    "    with open(collect, \"a\") as targetFile:\n",
    "        \n",
    "        for seed in  seedArray:\n",
    "            sourcePath = source.replace(\"s_re\",str(seed))\n",
    "            if os.path_exist(sourcePath):\n",
    "                context += fread(source,\"ZL\") + \"\\n\"\n",
    "            else:\n",
    "                continue\n",
    "# def w_locCombine(BC, J, D, L, P, m, phys):\n",
    "#     folder = creatDir()\n",
    "#     source = creatCpName()\n",
    "#     collect = creatColName()\n",
    "#     source += folder + source\n",
    "#     collect += folder + collect\n",
    "    \n",
    "#     with open(collect, \"a\") as targetFile:\n",
    "        \n",
    "#         for seed in  seedArray:\n",
    "#             sourcePath = source.replace(\"s_re\",str(seed))\n",
    "#             if os.path_exist(sourcePath):\n",
    "#                 context += fread(source,\"ZL\") + \"\\n\"\n",
    "#             else\n",
    "#                 continue\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    # file = sys.argv[1]\n",
    "    file = \"/home/aronton/tSDRG_random/Subpy/parameterRead/2025/2025_6_1/Spin15_L7_Jdis150_Dim000_P10_BC=OBC_chi40_partition=scopion4_seed1=1_seed2=10000_ds=50_task=submit_H8_M26_S35.txt\"\n",
    "    arg = []\n",
    "    # Jstr = [f\"Jdis{str(i).zfill(3)}\" for i in range(int(J),int(J)+1)]\n",
    "    # Jstr = [f\"Jdis{str(i).zfill(3)}\" for i in range(30,81,50)]\n",
    "\n",
    "    # Dstr = [f\"Dim{str(i).zfill(3)}\" for i in range(101)]\n",
    "    # Lstr = [f\"L{num}\" for num in range(31, 255, 32)]  # 只有 L512\n",
    "    # Lstr = [f\"L{num}\" for num in range(64, 129, 64)]  # 只有 L512\n",
    "    a = scriptCreator.para(\"read\",file)\n",
    "    parameterlist = a.para\n",
    "    para=scriptCreator.paraList1(parameterlist[\"L\"],parameterlist[\"J\"],parameterlist[\"D\"],parameterlist[\"S\"])\n",
    "    BC = parameterlist[\"BC\"]\n",
    "    Pdis = parameterlist[\"Pdis\"]\n",
    "    chi = \"m\" + str(parameterlist[\"chi\"])\n",
    "    s1 = int(parameterlist[\"S\"][\"S1\"])\n",
    "    s2 = int(parameterlist[\"S\"][\"S2\"])\n",
    "    # s1 = int(sys.argv[2])\n",
    "    # s2 = int(sys.argv[3])\n",
    "    # s1 = 1\n",
    "    # s2 = 20\n",
    "    for s in [\"ZL\",\"corr1\",\"corr2\",\"string\",\"J_list\",\"energy\",\"dimerization\",\"w_loc\",\"seed\"]:\n",
    "        for L in para.L_str:\n",
    "            for J in para.J_str:\n",
    "                    arg.append((BC, J, para.D_str[0], L, f\"P{Pdis}\", f\"{chi}\", s, s1, s2))\n",
    "    # s1 = 1\n",
    "    # s2 = 30000\n",
    "    # for s in [\"ZL\",\"corr1\",\"corr2\",\"string\",\"J_list\",\"energy\",\"dimerization\",\"w_loc\",\"seed\"]:\n",
    "    #     for L in [\"L31\",\"L63\",\"L127\"]:\n",
    "    #         for J in [\"Jdis030\",\"Jdis080\"]:\n",
    "    #                 arg.append((\"OBC\", J, \"Dim000\", L, \"P10\", \"m40\", s, s1, s2))\n",
    "    # print(Jstr)\n",
    "    # print(Lstr)\n",
    "    print(arg)         \n",
    "\n",
    "    def fun(arg):\n",
    "        # print(\"---------------------col--------------------\\n\")\n",
    "        # with multiprocessing.Pool(processes=10) as pool:\n",
    "        #     results1 = pool.starmap(Combine, arg)\n",
    "        arg = []\n",
    "        print(\"---------------------ave--------------------\\n\")\n",
    "        for s in [\"corr1\"]:\n",
    "            for L in para.L_str:\n",
    "                for J in para.J_str:\n",
    "                        arg.append((BC, J, para.D_str[0], L, f\"P{Pdis}\", f\"{chi}\", s, 1, 5))\n",
    "        print(arg)\n",
    "        with multiprocessing.Pool(processes=10) as pool:\n",
    "                pool.starmap(average, arg)\n",
    "        # print(\"---------------------del--------------------\\n\")\n",
    "        # with multiprocessing.Pool(processes=20) as pool:\n",
    "        #     results1 = pool.starmap(checkAndDelete, arg)\n",
    "            \n",
    "    # 計算函數執行時間\n",
    "    execution_time = timeit.timeit(lambda: fun(arg), number=1)\n",
    "\n",
    "    # 執行並顯示結果\n",
    "    # results1, results2 = fun(arg)\n",
    "    print(f\"Execution time: {execution_time} seconds\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9de3110f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8854:x1,x2,corr 0,1,-2.996937335799061 0,2,1.97376495523938 0,3,-1.998021655127982\n",
      "8853:x1,x2,corr 0,1,-3.745948182553837 0,2,0.2453484930166853 0,3,-0.1889316073438908\n",
      "8852:x1,x2,corr 0,1,-3.271012350805049 0,2,1.994158965794976 0,3,-1.720935612437799\n",
      "8851:x1,x2,corr 0,1,-3.11114925737843 0,2,2.233720245882107 0,3,-1.879672001460595\n",
      "8860:x1,x2,corr 0,1,-3.686362816578141 0,2,1.03070356819693 0,3,-0.7290280877598938\n",
      "8851:x1,x2,corr 0,1,-3.11114925737843 0,2,2.233720245882107 0,3,-1.879672001460595\n",
      "8852:x1,x2,corr 0,1,-3.271012350805049 0,2,1.994158965794976 0,3,-1.720935612437799\n",
      "8853:x1,x2,corr 0,1,-3.745948182553837 0,2,0.2453484930166853 0,3,-0.1889316073438908\n",
      "8854:x1,x2,corr 0,1,-2.996937335799061 0,2,1.97376495523938 0,3,-1.998021655127982\n",
      "8860:x1,x2,corr 0,1,-3.686362816578141 0,2,1.03070356819693 0,3,-0.7290280877598938\n"
     ]
    }
   ],
   "source": [
    "# 讀取檔案內容\n",
    "with open(\"/home/aronton/tSDRG_random/tSDRG/Main_15/data_collect/OBC/Jdis100/Dim000/L23_P10_m40/corr1_L23_P10_m40_Jdis100_Dim000.txt\", \"r\") as file:\n",
    "    context = file.read()\n",
    "context = \"\"\"8854:x1,x2,corr 0,1,-2.996937335799061 0,2,1.97376495523938 0,3,-1.998021655127982\n",
    "8853:x1,x2,corr 0,1,-3.745948182553837 0,2,0.2453484930166853 0,3,-0.1889316073438908\n",
    "8852:x1,x2,corr 0,1,-3.271012350805049 0,2,1.994158965794976 0,3,-1.720935612437799\n",
    "8851:x1,x2,corr 0,1,-3.11114925737843 0,2,2.233720245882107 0,3,-1.879672001460595\n",
    "8860:x1,x2,corr 0,1,-3.686362816578141 0,2,1.03070356819693 0,3,-0.7290280877598938\"\"\"\n",
    "print(context)\n",
    "# 定義排序函數\n",
    "def SortContext(context):\n",
    "    # 分割每一行，並過濾掉空行\n",
    "    lines = [line for line in context.strip().split(\"\\n\") if line]\n",
    "    pairs = []\n",
    "    for line in lines:\n",
    "        # 確保行中包含冒號\n",
    "        if ':' in line:\n",
    "            key_value = line.split(\":\", 1)\n",
    "            # 確保拆分後有兩個元素\n",
    "            if len(key_value) == 2:\n",
    "                key, value = key_value\n",
    "                try:\n",
    "                    # 將鍵轉換為整數\n",
    "                    key_int = int(key.strip())\n",
    "                    value = value.strip()\n",
    "                    pairs.append((key_int, value))\n",
    "                except ValueError:\n",
    "                    # 如果鍵不是整數，則跳過該行\n",
    "                    continue\n",
    "    # 根據鍵進行排序\n",
    "    sorted_pairs = sorted(pairs, key=lambda x: x[0])\n",
    "    # 重建排序後的內容\n",
    "    sorted_lines = [f\"{key}:{value}\" for key, value in sorted_pairs]\n",
    "    return \"\\n\".join(sorted_lines)\n",
    "\n",
    "# 輸出排序後的內容\n",
    "sorted_context = SortContext(context)\n",
    "print(sorted_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e553bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/aronton/tSDRG_random/tSDRG/Main_15/data_collect/OBC/Jdis100/Dim000/L23_P10_m40/corr1_L23_P10_m40_Jdis100_Dim000.txt\", \"r\") as file:\n",
    "    context = file.read()\n",
    "\n",
    "def SortContext(context):\n",
    "    context = context.split(\"\\n\")\n",
    "    context = [x.split(\":\") for x in context ]\n",
    "    # print(context)\n",
    "    sorted_context = sorted(context, key=lambda x: int(x[0]))\n",
    "    print(sorted_context)\n",
    "    # sorted_context = [x[0]+\":\"x[1] for x in sorted_context]\n",
    "    # context = \"\\n\".join(sorted_context)    \n",
    "    # return context\n",
    "# print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e57de43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ZL\" in ('PBC', 'Jdis030', 'Dim030', 'L64', 'P10', 'm31', 'ZL', 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4db0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "/dicos_ui_home/aronton/tSDRG_random/tSDRG/Main_15/data_collect/OBC/Jdis030/Dim000/L16_P10_m40/corr1_L16_P10_m40_Jdis030_Dim000.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
